{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2066457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Don't collapse Pandas Dataframes:\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Collection & Preparation:\n",
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "df = df[['spam', 'text']]\n",
    "df['spam'] = df['spam'].apply(lambda row: True if row == 'spam' else False) # Convert Text Labeled as 'Spam' to True, else False\n",
    "df['text'] = df['text'].apply(lambda row: row.lower().translate(str.maketrans('', '', string.punctuation))) # Clean Data: lowercase, remove punctuation\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDA:\n",
    "## Spam Examples:\n",
    "print('Spam Examples:')\n",
    "for text in df[df['spam'] == True].iloc[:5]['text']:\n",
    "    print(text)\n",
    "\n",
    "print('\\n')\n",
    "## Non-Spam Examples:\n",
    "print('Non-Spam Examples:')\n",
    "for text in df[df['spam'] == False].iloc[:5]['text']:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "## Split Dataset into Training and Validation Datasets:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.loc[:, 'text'].values\n",
    "print('\\nFeature Dataset Shape: (instances, features)')\n",
    "print('Total Dataset shape (X): {0}'.format(X.shape))\n",
    "print(X)\n",
    "y = df.loc[:, 'spam'].values.astype(np.float32).ravel() # Outcome = 1/0; Success/Failure\n",
    "print('\\nTrue Outcomes (Examples) shape (y): {0}'.format(y.shape))\n",
    "print(y)\n",
    "print('\\n')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42) # From Module: sklearn.model_selection; test_size = % allocated to Validation Dataset\n",
    "\n",
    "print('Training Feature shape (X_train): {0}'.format(X_train.shape))\n",
    "X_train_df = pd.DataFrame(X_train, columns = ['text'])\n",
    "print('Training Outcome shape (y_train): {0}'.format(y_train.shape))\n",
    "y_train_df = pd.DataFrame(y_train, columns = ['spam'])\n",
    "print('Validation Feature shape (X_test): {0}'.format(X_test.shape))\n",
    "X_test_df = pd.DataFrame(X_test, columns = ['text'])\n",
    "print('Validation Outcome shape (y_test): {0}'.format(y_test.shape))\n",
    "y_test_df = pd.DataFrame(y_test, columns = ['spam'])\n",
    "\n",
    "training_data = pd.concat([y_train_df, X_train_df], axis=1)\n",
    "\n",
    "training_data_spam_true = training_data[training_data['spam'] == 1.0]\n",
    "training_data_spam_false = training_data[training_data['spam'] == 0.0]\n",
    "# training_data_spam_true.head()\n",
    "# training_data_spam_false.head()\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.DataFrame(y_train, columns = ['spam'])\n",
    "percent_training_data_text_labeled_as_spam_true = y_train_df['spam'].mean()\n",
    "print('% of text in training outcome data that are labeled as \"spam\": {0}%'.format(percent_training_data_text_labeled_as_spam_true * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d97eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "## Clean Training Data: (Spam = True)\n",
    "training_data_spam_true_list = training_data_spam_true['text'].astype(str).tolist() # Turn DataFrame to List\n",
    "training_data_spam_true_string = ''.join(training_data_spam_true_list) # Combine List Values into a Single String\n",
    "training_data_spam_true_string = training_data_spam_true_string.translate(str.maketrans('', '', string.punctuation)) ## Remove Punctuation Characters\n",
    "training_data_spam_true_string = training_data_spam_true_string.replace('\\n','') ## Remove Line Breaks\n",
    "training_data_spam_true_string = re.sub(r'[0-9]+', '', training_data_spam_true_string) ## Remove Numerical Characters\n",
    "training_data_spam_true_string = training_data_spam_true_string.lower() ## Lowercase Characters\n",
    "\n",
    "#######################\n",
    "## Clean Training Data: (Spam = False)\n",
    "training_data_spam_false_list = training_data_spam_false['text'].astype(str).tolist() # Turn DataFrame to List\n",
    "training_data_spam_false_string = ''.join(training_data_spam_false_list) # Combine List Values into a Single String\n",
    "training_data_spam_false_string = training_data_spam_false_string.translate(str.maketrans('', '', string.punctuation)) ## Remove Punctuation Characters\n",
    "training_data_spam_false_string = training_data_spam_false_string.replace('\\n','') ## Remove Line Breaks\n",
    "training_data_spam_false_string = re.sub(r'[0-9]+', '', training_data_spam_false_string) ## Remove Numerical Characters\n",
    "training_data_spam_false_string = training_data_spam_false_string.lower() ## Lowercase Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2acfd41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "## Get a List of All Text where spam == True\n",
    "training_data_spam_true_word_list = training_data_spam_true_string.split()\n",
    "# print(training_data_spam_true_word_list)\n",
    "\n",
    "#############################################\n",
    "## Get a List of All Text where spam == False\n",
    "training_data_spam_false_word_list = training_data_spam_false_string.split()\n",
    "# print(training_data_spam_false_word_list)\n",
    "\n",
    "#############################\n",
    "## Get a List of Common Words where spam == True AND spam == False\n",
    "training_data_common_word_list = set(training_data_spam_true_word_list).intersection(set(training_data_spam_false_word_list))\n",
    "# print(training_data_common_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Create \"Bag of Words\" (via creating dictionaries)\n",
    "probability_spam_true_list = []\n",
    "for common_word in training_data_common_word_list:\n",
    "    probability_spam_true = training_data_spam_true_word_list.count(common_word) / len(training_data_spam_true_word_list)\n",
    "    probability_spam_true_list.append(probability_spam_true)\n",
    "\n",
    "####################################################\n",
    "## Create \"Bag of Words\" (via creating dictionaries)\n",
    "probability_spam_false_list = []\n",
    "for common_word in training_data_common_word_list:\n",
    "    probability_spam_false = training_data_spam_false_word_list.count(common_word) / len(training_data_spam_false_word_list)\n",
    "    probability_spam_false_list.append(probability_spam_false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acde0de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame(training_data_common_word_list, columns=['word'])\n",
    "prob_spam_true_df = pd.DataFrame(probability_spam_true_list, columns=['prob spam true'])\n",
    "prob_spam_false_df = pd.DataFrame(probability_spam_false_list, columns=['prob spam false'])\n",
    "spam_probabilities_df = pd.concat([word_df, prob_spam_true_df, prob_spam_false_df], axis=1)\n",
    "spam_probabilities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text_label_via_bag_of_words(list_of_text, df, percent_training_data_text_labeled_as_spam_true):\n",
    "    valid_words_list = []\n",
    "    for word in list_of_text:\n",
    "        # print('word: {0}'.format(word))\n",
    "        if word in training_data_common_word_list:\n",
    "            valid_words_list.append(word)\n",
    "        else:\n",
    "            pass\n",
    "            # print(\"'{0}' is not a valid word\".format(word))\n",
    "    # print('valid words: {0}'.format(valid_words_list))\n",
    "    \n",
    "    probability_spam_false_list = []\n",
    "    probability_spam_true_list = []\n",
    "    for valid_word in valid_words_list:\n",
    "        for index, row in df.iterrows():\n",
    "            word = row['word']\n",
    "            probability_spam_true = row['prob spam true']\n",
    "            probability_spam_false = row['prob spam false']\n",
    "            \n",
    "            if valid_word == word:\n",
    "                # print('valid word matched: {0}'.format(valid_word))\n",
    "                probability_spam_false_list.append(probability_spam_false)\n",
    "                probability_spam_true_list.append(probability_spam_true)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    word_df = pd.DataFrame(valid_words_list, columns=['word'])\n",
    "    probability_spam_true_df = pd.DataFrame(probability_spam_true_list, columns=['prob spam true'])\n",
    "    probability_spam_false_df = pd.DataFrame(probability_spam_false_list, columns=['prob spam false'])\n",
    "    predicted_labels_per_word_df = pd.concat([word_df, probability_spam_true_df, probability_spam_false_df], axis=1)\n",
    "    # print(predicted_labels_per_word_df)\n",
    "    \n",
    "    # Calculate spam True/False scores as sum of logs for all probabilities:\n",
    "    text_spam_true_score = sum([np.log(p) for p in probability_spam_true_list]) + np.log(percent_training_data_text_labeled_as_spam_true)\n",
    "    text_spam_false_score = sum([np.log(p) for p in probability_spam_false_list]) + np.log(1-percent_training_data_text_labeled_as_spam_true)\n",
    "    # Label as spam = True if text_spam_true_score >= text_spam_false_score\n",
    "    spam_score = (text_spam_true_score >= text_spam_false_score)\n",
    "    # print('Spam = True Score: {0}'.format(text_spam_true_score))\n",
    "    text_spam_true_score_list = [text_spam_true_score]\n",
    "    # print('Spam = False Score: {0}'.format(text_spam_false_score))\n",
    "    text_spam_false_score_list = [text_spam_false_score]\n",
    "    text = ' '.join(list_of_text) # Combine List Values into a Single String\n",
    "    # print('Text \"{0}\" is Spam: {1}'.format(text, spam_score))\n",
    "    text_spam_score_list = [spam_score]\n",
    "    text_list = [text]\n",
    "    predictions_df = pd.DataFrame(text_list, columns=['text'])\n",
    "    text_spam_score_df = pd.DataFrame(text_spam_score_list, columns=['spam'])\n",
    "    spam_true_score_df = pd.DataFrame(text_spam_true_score_list, columns=['spam true score'])\n",
    "    spam_false_score_df = pd.DataFrame(text_spam_false_score_list, columns=['spam false score'])\n",
    "    predictions_df = pd.concat([predictions_df, text_spam_score_df, spam_true_score_df, spam_false_score_df], axis=1)\n",
    "    # print(predictions_df)\n",
    "    return predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a95b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text = 'urgent call this number'\n",
    "predictions_df = predict_text_label_via_bag_of_words(text.split(), spam_probabilities_df, percent_training_data_text_labeled_as_spam_true)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e41e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'hey do you want to go a movie tonight'\n",
    "predictions_df = predict_text_label_via_bag_of_words(text.split(), spam_probabilities_df, percent_training_data_text_labeled_as_spam_true)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'offer for unlimited money call now'\n",
    "predictions_df = predict_text_label_via_bag_of_words(text.split(), spam_probabilities_df, percent_training_data_text_labeled_as_spam_true)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'are you at class yet'\n",
    "predictions_df = predict_text_label_via_bag_of_words(text.split(), spam_probabilities_df, percent_training_data_text_labeled_as_spam_true)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e50f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate\n",
    "X_test_df = pd.DataFrame(X_test, columns=['text'])\n",
    "X_test_list = X_test_df['text'].to_list()\n",
    "\n",
    "validation_predictions_df = pd.DataFrame()\n",
    "for text in X_test_list:\n",
    "    predictions_df = predict_text_label_via_bag_of_words(text.split(), spam_probabilities_df, percent_training_data_text_labeled_as_spam_true)\n",
    "    validation_predictions_df = validation_predictions_df.append(predictions_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e03286c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_predictions_df = validation_predictions_df.drop(columns=['spam true score','spam false score'])\n",
    "validation_predictions_df.reset_index(drop=True, inplace=True)\n",
    "validation_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effeb138",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.concat([X_test_df, y_test_df], axis=1)\n",
    "spam_boolean_list = []\n",
    "for index, row in validation_data.iterrows():\n",
    "    spam = row['spam']\n",
    "    if spam == 1.0:\n",
    "        spam_boolean_list.append(True)\n",
    "    else:\n",
    "        spam_boolean_list.append(False)\n",
    "\n",
    "validation_data = validation_data.drop(columns=['spam'])\n",
    "spam_boolean_df = pd.DataFrame(spam_boolean_list, columns=['spam'])\n",
    "validation_data = pd.concat([validation_data, spam_boolean_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_prediction_true_df = validation_predictions_df[(validation_predictions_df['spam'] == True)]\n",
    "spam_prediction_false_df = validation_predictions_df[(validation_predictions_df['spam'] == False)]\n",
    "validation_data_true_df = validation_data[(validation_data['spam'] == True)]\n",
    "validation_data_false_df = validation_data[(validation_data['spam'] == False)]\n",
    "\n",
    "validation_predictions_df.compare(validation_data, keep_equal=False)\n",
    "\n",
    "\n",
    "true_positives_df = pd.merge(validation_data_true_df, spam_prediction_true_df, how='left', on='text') # text = spam; prediction = spam\n",
    "false_positives_df = pd.merge(spam_prediction_true_df, validation_data_false_df, how='left', on='text') # text = spam; prediction = spam\n",
    "true_negatives_df = pd.merge(validation_data_false_df, spam_prediction_false_df, how='left', on='text') # text = spam; prediction = spam\n",
    "false_negatives_df = pd.merge(spam_prediction_false_df, validation_data_true_df, how='left', on='text') # text = spam; prediction = spam\n",
    "\n",
    "# true_positives_count = true_positives_df['text'].count()\n",
    "# false_positives_count = false_positives_df['text'].count()\n",
    "# true_negatives_count = true_negatives_df['text'].count()\n",
    "# false_negatives_count = false_negatives_df['text'].count()\n",
    "\n",
    "true_positives_count = true_positives_df[(true_positives_df['spam_y'] == True)]['spam_y'].count()\n",
    "false_positives_count = false_positives_df[(false_positives_df['spam_y'] == False)]['spam_y'].count()\n",
    "true_negatives_count = true_negatives_df[(true_negatives_df['spam_y'] == False)]['spam_y'].count()\n",
    "false_negatives_count = false_negatives_df[(false_negatives_df['spam_y'] == True)]['spam_y'].count()\n",
    "\n",
    "print('TP: {0}'.format(true_positives_count))\n",
    "print('FP: {0}'.format(false_positives_count))\n",
    "print('TN: {0}'.format(true_negatives_count))\n",
    "print('FP: {0}'.format(false_negatives_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = true_positives_count / (true_positives_count + false_negatives_count)\n",
    "precision = true_positives_count / (true_positives_count + false_positives_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac31456",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Spam Detection Recall: {0}%'.format(recall)) # Recall = TP / (TP + FN)\n",
    "print('Spam Detection Precision: {0}%'.format(precision)) # Precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe8add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756b895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e4df36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d42aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1419df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b8b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
